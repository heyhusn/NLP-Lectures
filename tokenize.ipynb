{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heyhusn/NLP-Lectures/blob/main/tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vprSFnHbf9z",
        "outputId": "c538a094-3f02-4545-9383-070a25a4f736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 10.5 MB/s eta 0:00:00\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.9.13-cp38-cp38-win_amd64.whl (267 kB)\n",
            "     ------------------------------------- 267.7/267.7 kB 16.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\win10\\anaconda3\\envs\\development\\lib\\site-packages (from nltk) (4.62.3)\n",
            "Requirement already satisfied: click in c:\\users\\win10\\anaconda3\\envs\\development\\lib\\site-packages (from nltk) (8.0.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\win10\\anaconda3\\envs\\development\\lib\\site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\win10\\anaconda3\\envs\\development\\lib\\site-packages (from click->nltk) (0.4.4)\n",
            "Installing collected packages: regex, nltk\n",
            "Successfully installed nltk-3.7 regex-2022.9.13\n",
            "\n",
            "[notice] A new release of pip available: 22.1.2 -> 22.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYX2Zm6Abf95"
      },
      "outputs": [],
      "source": [
        "corpus=\"\"\"Hello Welcome,to Krish Naik's NLP Tutorials.\n",
        "Please do watch the entire course! to become expert in NLP.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4Wm6mxobf95",
        "outputId": "a859d3fd-5ea5-454d-9a14-aadacf772d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Welcome,to Krish Naik's NLP Tutorials.\n",
            "Please do watch the entire course! to become expert in NLP.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_64R8N2Cbf96"
      },
      "outputs": [],
      "source": [
        "##  Tokenization\n",
        "## Sentence-->paragraphs\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr-hDw1nbf97"
      },
      "outputs": [],
      "source": [
        "documents=sent_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9HHLU1abf98",
        "outputId": "8e652bf3-0c19-4913-918b-262f628ace6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRLvKmI4bf99",
        "outputId": "7f107a61-9a4c-4578-c3d9-7bd67af4a422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Welcome,to Krish Naik's NLP Tutorials.\n",
            "Please do watch the entire course!\n",
            "to become expert in NLP.\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOmYylRGbf9-"
      },
      "outputs": [],
      "source": [
        "## Tokenization\n",
        "## Paragraph-->words\n",
        "## sentence--->words\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htDPbNqCbf9-",
        "outputId": "9bb8031c-f662-4aa9-c52d-1e6df85fcdb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " ',',\n",
              " 'to',\n",
              " 'Krish',\n",
              " 'Naik',\n",
              " \"'s\",\n",
              " 'NLP',\n",
              " 'Tutorials',\n",
              " '.',\n",
              " 'Please',\n",
              " 'do',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'course',\n",
              " '!',\n",
              " 'to',\n",
              " 'become',\n",
              " 'expert',\n",
              " 'in',\n",
              " 'NLP',\n",
              " '.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0cW66N3bf9_",
        "outputId": "0cdf5aa5-5ee5-4d43-95bf-792154822d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hello', 'Welcome', ',', 'to', 'Krish', 'Naik', \"'s\", 'NLP', 'Tutorials', '.']\n",
            "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
            "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5P2Xqxzbf-A"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eZR9-G9bf-A",
        "outputId": "802b3a04-b27f-4cac-ab5e-6254f223d0fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " ',',\n",
              " 'to',\n",
              " 'Krish',\n",
              " 'Naik',\n",
              " \"'\",\n",
              " 's',\n",
              " 'NLP',\n",
              " 'Tutorials',\n",
              " '.',\n",
              " 'Please',\n",
              " 'do',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'course',\n",
              " '!',\n",
              " 'to',\n",
              " 'become',\n",
              " 'expert',\n",
              " 'in',\n",
              " 'NLP',\n",
              " '.']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordpunct_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGQyH_Cqbf-A"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-jP7DBNbf-A"
      },
      "outputs": [],
      "source": [
        "tokenizer=TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY9nsjVjbf-B",
        "outputId": "53697185-1d0e-4066-9a12-a4041fd66b88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " ',',\n",
              " 'to',\n",
              " 'Krish',\n",
              " 'Naik',\n",
              " \"'s\",\n",
              " 'NLP',\n",
              " 'Tutorials.',\n",
              " 'Please',\n",
              " 'do',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'course',\n",
              " '!',\n",
              " 'to',\n",
              " 'become',\n",
              " 'expert',\n",
              " 'in',\n",
              " 'NLP',\n",
              " '.']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.tokenize(corpus)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}