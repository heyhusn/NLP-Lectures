{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heyhusn/NLP-Lectures/blob/main/2.%20Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZGitSKkb6ha"
      },
      "source": [
        "## Stemming\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DoUOWH5b6hg"
      },
      "outputs": [],
      "source": [
        "## Classification Problem\n",
        "## Comments of product is a positive review or negative review\n",
        "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
        "\n",
        "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIQ3ZV0b6hj"
      },
      "source": [
        "### PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOp9FXmUb6hk"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft4WU2Mtb6hm"
      },
      "outputs": [],
      "source": [
        "stemming=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aiuwcaeb6hn",
        "outputId": "7eda9141-4b07-4c01-ea16-952436223dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+stemming.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uxFbbM7b6hp",
        "outputId": "194bb707-13ee-45e8-d038-da9da6263609"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'congratul'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem('congratulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQAiZMWbb6hs",
        "outputId": "40fba7be-7fba-47e5-e50d-39bfb3780f24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sit'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem(\"sitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spGDi-pnb6hv"
      },
      "source": [
        "### RegexpStemmer class\n",
        "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example.  $ sign just remove from the last of expression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpvFZJYrb6hx"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import RegexpStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "oSJ-4M_qb6hy"
      },
      "outputs": [],
      "source": [
        "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFyY4ySXb6hz",
        "outputId": "b1f2341b-fb48-4d67-92be-d4ad0cb3c08a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'eat'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_stemmer.stem('eating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF49PW_Mb6h0",
        "outputId": "838b4b49-beda-4802-d58d-7cdbbe426661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ingeat'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_stemmer.stem('ingeating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V96ygFLb6h1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdXrhqS8b6h2"
      },
      "source": [
        "### Snowball Stemmer\n",
        " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2kFmcn9b6h2"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0_37hKjb6h3"
      },
      "outputs": [],
      "source": [
        "snowballsstemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLGPNJ29b6h4",
        "outputId": "fc134e3d-9779-4a62-b2e2-c167dc1afc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+snowballsstemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaZRQ55qb6h5",
        "outputId": "6a85c053-f22d-47df-ffc4-7f63cbaeeda9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fairli', 'sportingli')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DZhkzEb6h6",
        "outputId": "c6ae073c-937c-4db5-8580-7a0f33e768c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOJt4H72b6h7",
        "outputId": "40be53ca-620d-48c1-b495-7cb5b76a293b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'goe'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snowballsstemmer.stem('goes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd21sBYub6h9",
        "outputId": "eb5a33c4-3371-4f74-c987-5dfefe707454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'goe'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem('goes')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}